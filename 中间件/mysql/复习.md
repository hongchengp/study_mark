

### DQL

![image-20240912150225901](../../../AppData/Roaming/Typora/typora-user-images/image-20240912150225901.png)

![image-20240912151442588](../../../AppData/Roaming/Typora/typora-user-images/image-20240912151442588.png)

![image-20240912151454672](../../../AppData/Roaming/Typora/typora-user-images/image-20240912151454672.png)

![image-20240912151506315](../../../AppData/Roaming/Typora/typora-user-images/image-20240912151506315.png)

![image-20240912151816657](../../../AppData/Roaming/Typora/typora-user-images/image-20240912151816657.png)

![image-20240912151858935](../../../AppData/Roaming/Typora/typora-user-images/image-20240912151858935.png)

![image-20240912152046812](../../../AppData/Roaming/Typora/typora-user-images/image-20240912152046812.png)

![image-20240912152133199](../../../AppData/Roaming/Typora/typora-user-images/image-20240912152133199.png)

![image-20240912152237919](../../../AppData/Roaming/Typora/typora-user-images/image-20240912152237919.png)

![image-20240912152334935](../../../AppData/Roaming/Typora/typora-user-images/image-20240912152334935.png)



## 索引



### B+tree

![image-20240912163405364](../../../AppData/Roaming/Typora/typora-user-images/image-20240912163405364.png)

![image-20240912163515822](../../../AppData/Roaming/Typora/typora-user-images/image-20240912163515822.png)



### hash

![image-20240912163712542](../../../AppData/Roaming/Typora/typora-user-images/image-20240912163712542.png)

![image-20240912163814926](../../../AppData/Roaming/Typora/typora-user-images/image-20240912163814926.png)

![image-20240912164132677](../../../AppData/Roaming/Typora/typora-user-images/image-20240912164132677.png)

为什么InnoDB选B+：

1. 每个数据都在同一行

2. 除了叶子节点，非叶子节点都是存的子节点的指针，所以它的儿子多，树就宽 和 矮（矮就代表磁盘IO就少，IO数 = 层数）

3. 可以支持范围查询，因为叶子节点是双向链表





### 索引类型

![image-20240912164656971](../../../AppData/Roaming/Typora/typora-user-images/image-20240912164656971.png)

![image-20240912164930841](../../../AppData/Roaming/Typora/typora-user-images/image-20240912164930841.png)

![image-20240912165143086](../../../AppData/Roaming/Typora/typora-user-images/image-20240912165143086.png)

![image-20240912165156732](../../../AppData/Roaming/Typora/typora-user-images/image-20240912165156732.png)



#### 为什么二级索引存主键不存完整的数据

1. 数据冗余，存了太多无意义的数据
2. 更改，需要将所有的索引的数据都改变
3. 对于数据库来说，**主键 和 索引，就相当于指针**，有了它就是有了数据



### 最左前缀法则

因为是 根据排序规则

比如 index（a, b, c) 

先根据 a then b then c

所以排序要将前缀 带入 select



### 范围查询




这是为什么呢？



### 索引失效

#### 索引列运算

因为是根据完整的 字段排序的，改变了，就不能二分查找（其实是多叉 查找）



#### 字符串不加引号





#### 模糊查询

如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。



#### or连接条件

比如 select * from user where name =“yyj” or age >= 30

name 是最左前缀，but age不是。那name 可以根据index找到，但是 age 不能用index，怎么办，只能全表查询。那就是 index + 全表

那不如直接全表



#### 数据分布影响

如果MySQL评估使用索引比全表更慢，则不使用索引



### Sql提示

这是干什么的

如果query可以使用多个索引

它应该用什么呢

它自己分析

但是我们可以给出sql提示



sql提示，告诉数据库，有多个index，我们更希望 用的index



### 索引覆盖（不用回表了）

尽量使用覆盖索引，减少select *。 那么什么是覆盖索引呢？ 覆盖索引是指 查询使用了索引，并 且需要返回的列，在该索引中已经全部能够找到 。

而我们如果一直使用select * 查询返回所有字段值，很容易就会造成回表 查询（除非是根据主键查询，此时只会扫描聚集索引）。

覆盖索引 节点包括 index字段 & 主键

而 子查询 + index 可以解决 大分页查询。因为1. return的字段少很多 2. 减少回表

select * from user where id in (select id from user where age > 20 limit 10000, 10 order by age asc)





### 前缀索引

就是对于 string，只用前几个字符就可以，不用开销更多



### 联合索引 & 单列索引

在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引， 而非单列索引。

**因为可能覆盖索引**





### 建立索引原则

1. select 经常用的
2. 主键不应该改变（因为页分裂 和 页合并），so不应该和业务相关，因为业务是会改变的
3. 主键应该 是自增的（防止页分裂）
4. 应该逻辑删除 （防止页合并）
5. 联合索引 > 单列索引 （因为联合索引 可以 减少回表查询）
6. index 不应该 容易变化





## 性能分析



### 执行频率

是读多，还是写多

读多，可以适量的数据冗余

写多，可以 提高范式化，因为减少数据冗余，写的开销小

index也是 数据冗余哦，冗余了 index字段 & 主键



### 慢日志

记录超过指定时间的sql





### profile 

记录sql语句每个阶段的耗时





### explain



就是，sql语句在内部是怎么执行的





## 优化

### Sql优化

一次插入很多 用批处理 or 自己开启事务

按主键的顺序插入，少 页分裂 or 页合并



### 主键优化

尽量的短

最好是 自增的（防止页分裂）

不要是uuid or 自然证件

不要对主键操作



### order by 优化

它还是和索引相关

它也符合 最左前缀法则



### group by

也是和索引相关的

也符合最左前缀法则



### limit 优化

如果不用索引的

它也是要一个一个排序的（file sort）

因此 还是要用索引

如果太慢了，就查看慢日志

有了index还是不行，为什么呢

因为它会回表查询

**为了减少回表，就用子查询**



### count优化

用count(*)



### update优化

对于事务来说

update会 导致上锁

但是如果没有索引，他就会从行锁 变成 表锁





## 锁

锁是用来并发的

如果是单个语句，是原子的，不用上锁的

so，锁应该是对于事务来说的

锁 就是解决并发中的对共享数据 互斥访问



为什么引入了 行锁，因为锁的颗粒度更小

so 如果说的颗粒度很大，尽可能的减少锁的颗粒多，在不改变互斥的情况，也就是对相同资源，同时只能一个

1. key mod hash （分段，但是可能会hash冲突，也很好了）
2. key 锁 （要对唯一标识上锁，但是要锁 可以一一映射，java中的 对象锁可以，go我现在还不知道）



### 全局锁

比如备份数据

为了一致性（C）,他就要全局上锁



### 表锁

锁的颗粒度最大，冲突最高，并发最低



### 元数据锁MDL

它存储的是表的结构，so开启事务时，它会上锁

防止数据的不一致性

比如，事务A 在 查数据，来了DDL, 要改结构，这不是寄了嘛

这些锁都有共享锁（读锁）和 排他锁（写锁）

比如，事务A在 DDL时，就是元数据排他锁



### 行锁

粒度最小，冲突最低，并发最高

行锁是对应，索引的，不是对于一行数据的

所以要建立索引哦



### 意向锁

为什么要有它呢

如果要加表锁，要等行锁结束，但是一行一行的找太慢了

所以，意向锁就像看门狗，有行锁就有它

当然都有共享锁和排他锁





### 间隙锁 & 临键锁

**他们的目的都是为了事务**，**防止在间隙中插入数据**





## InnoDB引擎

它和 另一个比

支持 行锁（颗粒多小），事务（ACID，而且通过 MVCC（trd_id, rollback_pointer）无锁隔离级别（是每一个事务都有自己的数据））

外键 （参照完整性）



### 内存架构

### buffer Pool

它就是缓存

使用缓存与批处理，来减少 磁盘IO

就是异步IO + 批处理 （异步IO一定要有一个缓冲区，比如线程池中的任务队列，消息队列）

### change Pool



### 自适应hash

它是数据的缓存

而且对于热点数据，他会自动生成hash

可以用O(1) 来精准的匹配

局部性原理



### log Buffer

存 log，因为log是顺序存储的，比数据存的更快，so都是先存 log的

当出入 redolog时，那这个事务就commit了，redolog保证了 持久性 和 一致性（undolog 也保证了，不过保证了 rollback的一致性，逻辑日志哦，在java，go事务的实现应该也是存储了 undolog）



### 数据隐藏字段

trx_id & trx_id_pointer

trx_id 记录当前数据是那个事务的

trx_id_pointer 是一个链表指针，指向它以前事务的数据

本质是 让数据 线程（事务）私有，保证并发安全

它加上 readView（读视图），then 快照读（根据 readView读取的数据）

if 事务 readView 只在 第一次读生成，后面时候读，都复用第一次的，它实现了 可重复读（readView一样，而数据只根据readView）

if 每次读 都生成当前的readView then 实现了 读已提交

幻读 也可以根据 MVCC解决，因为事务在执行 delete时，数据不会马上删除，而是直到没有操作和它相关才 删除，then 解决了幻读

都是无锁的

但是可串行化要通过锁，性能低



### undo 链

就是trx_id_pointer 指向的数据链

配合 readView (它是事务拥有的，当前事务id、活跃事务id（未提交的）、最大事务id、最大已分配事务id)

根据这个可以解决 读已提交（每次读时，都生成一个readView，读取已经提交的数据）

RR ，第一次读时生成readView，以后读都复用这个，就算别人提交了，也不会读

串行化，那就要锁了，要上间隙锁



而通过undo 链（存储在 undo log，用来回滚的）



### readView（读视图）

存储着 事务id信息

**当前事务id、活跃事务id（未提交的）、最大事务id、最大已分配事务id)**



### 快照读

就是读 符合 readView而不是最新数据



### MVCC 多版本并发控制

通过 undo链，trx_id, readView，锁来实现的
幻读，MVCC可以解决

但是 可串行化要 锁



而通过undo 链，可以实现无锁，效率更高



#### 读已提交

每次读都生成一个readView，从这个readView中读已经提交的（trd_id & 事务回滚链）



#### 可重复读

第一次读时，生成读视图（readView）

so每一次读时，只会读同一个数据



#### 幻读

可以用MVCC解决，因为又readView，如果新增的，因为readView，它会对新增的数据透明的

那删除的，它不会直接删除，会等到所有和它相关的数据都没有，才会删除

**MVCC是轻量级的，解决事务一致性**

那代价呢，用空间换时间（有了trd_id & 回滚链，相当于是事务私有的），回滚链是undolog中的



#### 可串行化

用锁实现的，行锁（间隙锁）







### 总结

1. 支持事务（redo，undo, trx_id, trx_id_poniter，锁）
2. 支持行锁（行锁，间隙锁和临间锁（为了幻读））
3. 支持外键（数据的参照完整性）





## 数据设计

### 数据冗余

#### 范式化

第一范式：字段是不可分的

第二范式：**字段完全依赖属于主键**（部分依赖）

第三范式：**字段直接依赖主键**（消除传递依赖）

是为了**数据一致性**，但是这样就会对于查询不好，因为要进行join查询



#### 反范式化

有意的数据冗余

它是**读多写少**，但是写不好，因为数据冗余，**对于冗余部分，都要改**



#### 索引

索引的那些字段，就是数据冗余。

so如果要改索引字段，那也要改很多（聚集索引改 & 索引也要改）

索引不能太多

为了防止回表，应该尽可能聚集索引



### 主键设计

对于B+Tree，如果聚集索引，**主键插入是无序的**，就有可能**页分裂**

so**主键应该是 不能改变的（不要和业务相关，因为业务是会变的），自增的**



### 删除

**如果删除，就会带来页合并**

so，可以用**逻辑删除**



### 表太大

用分表，防止B+Tree,层数高了



### 并发量太高



连接池 （有网络IO，就想到 连接池）

有IO 就想到 异步IO + 批处理

分库（就是增加资源，分布式）

数据不同：

​	水平分库： 根据key mod，在不同的表上，每张表结构相同，分片键应该 经常用 & 不容易变化，如果没有分片键 then 用路由表（数据冗余了，写时麻烦），产生了数据分片，如果表数量改变了怎么办，一致性不行，因为数据库数据是保底的，so就别改变咯，or 慢慢清洗

​	垂直：根据功能再细分，比如 People表 分成 上半身 下本身

​	

分布式

 	读写分离

​	但是引入了，管理开销，一致性（binlog），CAP

​	但是 可以应对 高流量，高数据，高可用（防止单点故障）

